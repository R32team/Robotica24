<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.ald.softbankrobotics.com/schema/choregraphe/project.xsd" xar_version="3">
  <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
    <bitmap>media/images/box/root.png</bitmap>
    <script language="4">
      <content>
        <![CDATA[]]>
      </content>
    </script>
    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
    <Timeline enable="0">
      <BehaviorLayer name="behavior_layer1">
        <BehaviorKeyframe name="keyframe1" index="1">
          <Diagram>
            <Box name="text image taker" id="1" localization="8" tooltip="This box contains a basic python script and can be used to create any python script box you would like.&#x0A;&#x0A;To edit its script, double-click on it." x="365" y="395">
              <bitmap>media/images/box/box-python-script.png</bitmap>
              <script language="4">
                <content>
                  <![CDATA[from naoqi import ALProxy
import pytesseract
from PIL import Image
import os

class OCRBehavior:
    def __init__(self, ip, port):
        self.tts = ALProxy("ALTextToSpeech", ip, port)
        self.photoCapture = ALProxy("ALPhotoCapture", ip, port)

    def capture_and_process_image(self):
        # Configure the photo capture settings
        self.photoCapture.setResolution(2)
        self.photoCapture.setPictureFormat("png")
        path = "/home/nao/recordings/cameras/"
        filename = "ocr_image.png"

        # Take the picture
        self.photoCapture.takePicture(path, filename)
        full_path = os.path.join(path, filename)

        # Process the image with OCR
        text = pytesseract.image_to_string(Image.open(full_path))
        return text

    def perform(self):
        text = self.capture_and_process_image()
        if text:
            self.tts.say("I read: %s" % text)
        else:
            self.tts.say("I couldn't detect any text.")

# Usage
# Replace 'your_robot_ip' and '9559' with your robot's IP and port
ocr_behavior = OCRBehavior("192.168.0.108", "robots port")
ocr_behavior.perform()]]>
                </content>
              </script>
              <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
              <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
              <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
              <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
            </Box>
            <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
            <Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" />
          </Diagram>
        </BehaviorKeyframe>
      </BehaviorLayer>
    </Timeline>
  </Box>
</ChoregrapheProject>
